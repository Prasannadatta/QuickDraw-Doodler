{
    "rnn": {
        "in_size": 4,
        "batch_size": 16,
        "num_epochs": 20,
        "learning_rate": 0.001,
        "enc_hidden_size": 128,
        "dec_hidden_size": 64,
        "attention_size": 64,
        "latent_size": 64,
        "num_lstm_layers": 4,
        "kl_div_coeff": 1,
        "num_annealing_epochs": 15,
        "dropout": 0.0,
        "decoder_activations": "leaky_relu"
    },

    "gan": {

    },

    "tcn": {

    },

    "cnn": {

    }
}